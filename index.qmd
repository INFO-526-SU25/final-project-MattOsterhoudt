---
title: "Men's NCAA March Madness Tournament Analysis"
subtitle: "INFO 526 - Summer 2025 - Final Project"
author: 
  - name: "Matt Osterhoudt"
    affiliations:
      - name: "School of Information, University of Arizona"
description: "This project will examine past NCAA Men's March Madness data in order to develop key insights and predictions utilizing data visualization through plot creation/interpretation."
format:
   html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
editor: visual
execute:
  warning: false
  echo: false
---

```{r setup}
# set theme for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 14))

# set width of code output
options(width = 65)

# set figure parameters for knitr
knitr::opts_chunk$set(
  fig.width = 7, # 7" width
  fig.asp = 0.618, # the golden ratio
  fig.retina = 3, # dpi multiplier for displaying HTML output on retina
  fig.align = "center", # center align figures
  dpi = 300 # higher dpi, sharper image
)
# install and load packages
if(!require(pacman))
  install.packages("pacman")

pacman::p_load(tidyverse,
               janitor,
               ggrepel,
               ggforce,
               here,
               scales,
               ggridges,
               kableExtra)

devtools::install_github("tidyverse/dsbox")

library(tidyverse)
```

## Introduction

March madness is the NCAA Division 1 annual basketball tournament. It is single-elimination based tournament, and the data I will be using ranges from 200-2024. 2020 is not included because of Covid. There are two data sets that will be used: Team Results and Public Picks. Let's start with the simpler one: the Public Picks data set contains the percentage of people who picked the team to win game in the rounds 64, 32, 16, 8, final 4, and finals for the 2024 year.

The second data set is Team Results, and contains data from 2008-2023. This data set contains more variables, such as PAKE (performance against Komputer expectations) and PASE (Performance against seed expectations), along with total historical games teams have played in the tournament as well as how often they have made top 64, 32, 16, 8, 4, finals, and champion. There are also a couple of indicator variables, such as f4percent and champpercent, which notes likelihood of a team getting at least 1 final four or at least 1 championship. Another data set that will be used is "matchup_by_year", which takes the matchup data, seed, and score difference by bracket round and year.

## Question 1: NCAA March Madness Tournament Analysis
**How well does past tournament performance from 2008-2023 correlate with predictions for the 2024 tournament?**

## Question 1 Introduction

My hypothesis for this question: Past team performance has little to no correlation with predictions for the 2024 tournament. I am interested to find out if there is any sort of correlation with how well a team has historically done in the tournament and public predictions. It's well known that most public pick results are determined by a wide range of more obvious factors, such as season standings, seeding, ...the list goes on. By visually analyzing the potential relationship between past performance and predictions, I hope to shed light on this as a potential indicator for tournament predictions.

The parts of the data I will be using from the public_picks data set is the f4 (public final four prediction percentage) variable. This variable, in conjunction with the team_results variables f4 and r64 variables (used to compute historic final 4 rates) will be our first measure in correlation. I will also use another variable, PASE (Performance Against Seed Expectations) to determine how public sentiment may or may not deviate from historical data, based on team quality.

## Question 1 Approach

For the first plot, I chose a simple scatter plot fitted with a linear regression model. The scatter plot allows us to visualize the spread of data points. With a linear trend line, we can also determine if there is a positive or negative relationship between historic final four data and public final four prediction rates. A scatter plot also allows us to use color to differentiate between the categorical PASE data, in which we will examine potential trends.

For the second plot, I chose to use a density ridge plot. The goal here is to find public prediction deviations across team quality by tier, which is why PASE will be used and categorized into tiered quartiles. I like that the density ridge allows us to stack the quartile distribution, which allows us to easily notice any data skew, spread, and/or outliers. 

## Question 1 Analysis

```{r}
#| label: load-dataset


team_results <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-03-26/team-results.csv') |>
  clean_names()
public_picks <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-03-26/public-picks.csv') |>
  clean_names()

# Changes the % into a numeric value by stripping "$"
public_picks <- public_picks |>
  mutate(public_f4_percentage = as.numeric(str_remove(f4, "%")))

# Computes the quantile breakpoints
pase_quantile <- quantile(team_results$pase, probs = c(0.25, 0.50, 0.75), na.rm = TRUE)

# Computes historical top 4 percentage and also the quantile labels based on breakpoint.
team_results <- team_results |>
  mutate(
    historical_f4_percentage = f4 / r64 * 100,
    pase_quant = cut(pase, breaks = c(-Inf, pase_quantile, +Inf), labels = c("Q1", "Q2", "Q3", "Q4"),
                     right = TRUE
                    )
  )

#team_results

# Using a join, selecting teams that appear in public_picks and team results
combined_data <- team_results |>
  select(team, historical_f4_percentage, pase_quant) |>
  inner_join(
    public_picks |>
      select(team, public_f4_percentage), by = "team"
  )
# Computing delta_f4 
combined_data <- combined_data |>
  mutate(
    delta_f4 = public_f4_percentage - historical_f4_percentage
  )

#combined_data

# First Plot: Scatterplot
ggplot(combined_data, aes(x = historical_f4_percentage, y = public_f4_percentage, color = pase_quant)) +
  geom_point(size = 2.5, alpha = .7, shape = 21, fill = "white", stroke = 1) +
  facet_zoom(
              xlim = c(0,30), 
              ylim = c(0,20), 
              zoom.size = 1) +
  coord_cartesian(ylim = c(0, 50)) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  scale_x_continuous("Historical Final Four (2008-2023)", labels = scales::percent_format(scale = 1)) +
  scale_y_continuous("Public Final Four Predictability (2004)", labels = scales::percent_format(scale = 1)) +
  scale_color_manual( name = "PASE by Quartile", values = c(
  "Q1" = "darkgreen", "Q2" = "blue", "Q3" = "purple", "Q4" = "red")) +
  labs(
    title = "NCAA March Madness: Historic Final 4 Appearances vs Public Final Four Predictions",
    color = "PASE Quartile",
    caption = "Source: TidyTuesday",
    subtitle = "Left Panel shows a zoomed-in view"
  ) +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold", size = 12),
    axis.title = element_text(size = 10),
    plot.subtitle = element_text(size = 10),
    plot.caption = element_text(hjust = 1,
                                face = "italic",
                                size = 6)
  ) 

# Second plot: Density Ridge
ggplot(combined_data, aes(x = delta_f4, y = pase_quant, fill = pase_quant)) +
  geom_density_ridges(alpha = 0.8, scale = 1.2) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_x_continuous(
    name = "Final 4: Public predictions minus Historic (%)",
    labels = percent_format(scale = 1),
    breaks = seq(-100, 40, by = 20)
  ) +
  labs(
       y = "PASE Quartile",
       title = "Final 4 Density Ridge Plot:\nPASE Quartiles vs. Public - Historic (%Î”)",
       caption = "Source: TidyTuesday") +
  theme_ridges() +
  theme(
    legend.position = "none",
    panel.grid.major.y = element_blank(),
    plot.caption = element_text(hjust = 1,
                                face = "italic",
                                size = 6) 
    )




```

## Question 1 Discussion

Teams with higher rate of final four appearances (from 2008-2023) appear to also receive higher public prediction rates. The scatter plot reveals a positive trend between the two. Past performance, therefore, may be considered as a guide for public sentiment. The outlier points are another thing to consider, and is most most likely why the linear regression line was as steep as it was. Without these outliers, as seen in the zoomed in plot, there is still a positive trend, although weaker in magnitude. 

Also, the density ridge plot revealed a little about how well the public predicts team by PASE ratings. A lot of the data spread was in the middle, with a few trends to the right (overestimating performance), but more to left (underestimating performance). This implies that the public tends to underestimate teams more often, especially teams with higher PASE ratings. However, the data is only limited to 2003-2008, and was only utilized for 2024 predictions. The analysis lacks any sort of trend over time.

## Question 2: NCAA March Madness Tournament Analysis 
**Are lower-seeded teams winning more frequently over time, and if so, by what level of magnitude?**

## Question 2 Introduction

Hypothesis: Overtime, there have been more upsets in the NCAA tournaments, with an increasing level of magnitude. This question utilizes a new data set called "matchups_by_year", which contains tabular data on every single matchup in the tournament, by year. To answer this question, I will be using the seed column, year column, and round column to compute additional data. Using these variables, I should be able to examine if any trends exist.

I am interested in answering this question because of the nature of game upsets; it goes against expectations for 16th seeded teams to defeat 1st seed teams, but it happens anyway. Analyzing this relationship is very useful to make NcAA tournament predictions. For morally ambiguous reasons, there are many out there who utilize such data when making sports bets. If there is a higher level of upset variance over time as hypothesized, then this would affect betting outcomes and the level of risk.

## Question 2 Approach

For the first plot, I chose to use a tiled heat-map plot. The color spread of a heat map depicts the frequency of upsets by round, and it's also very useful to show what is happening round by round over time. I combined years into blocks of four in order to determine the rate of upsets per "era". The frequency of upsets by round was computed by simply converting upsets into a boolean, then calculating the mean over a 4 year period.

For the second plot, I chose a box and whisker plot to depict upset magnitude, again by bracket and 4-year blocks. A box plot will strategically measure the distribution of seed difference over our time era ranges (2000-2024, in blocks of 4 years). For this plot, I calculated the seed difference and filtered by upset, returning matchups that had an upset and converting seed difference to a positive value. I decided to visually display the first 4 rounds (64, 32, 16, and 8 teams left) and also keep the 4-year range.

## Question 2 Analysis

```{r}
# Read in matchup data
matchups_by_year <-read_csv(here("data", "combined.csv")) 

# Filters the data to 2000-2024, computes upset, seed difference, and 4-year range
upsets_data <- matchups_by_year |>
  filter(year >= 2000, year <= 2024) |>
  mutate(
    round_of = factor(round_of, levels = c("64", "32", "16", "8", "4", "2")),
    upset = winning_team_seed > losing_team_seed,
    seed_difference = winning_team_seed - losing_team_seed,
    four_year_range = case_when(
      year <= 2003 ~ "2000-2003",
      year <= 2007 ~ "2004-2007",
      year <= 2011 ~ "2008-2011",
      year <= 2015 ~ "2012-2015",
      year <= 2020 ~ "2016-2020",
      TRUE ~ "2021-2024"
    ) |> 
      fct_relevel("2000-2003", "2004-2007", "2008-2011",
                  "2012-2015", "2016-2020", "2021-2024")
  )
    
#view(upsets_data)

# Groups data by four year range, round, and calculates upset percentage.
heatmap_data <- upsets_data |>
  group_by(four_year_range, round_of) |>
  summarize(upset_percentage = mean(upset) * 100, .groups = "drop")

#view(heatmap_data)
            
ggplot(heatmap_data, aes(x = four_year_range, y = round_of, fill = upset_percentage)) +
  geom_tile(color = "white") +
  geom_text(aes(label = percent(upset_percentage/100)),
            color = ifelse(heatmap_data$upset_percentage >= "40", "black", "white"), size = 3) +
  scale_fill_viridis_c(
    name = "% Upsets",
    option = "D",
    direction = 1) +
  labs(
    y = "Teams left per round",
    x = "4-year Range",
    title = "Frequency of Upsets by Round and 4 year range",
    caption = "Note: 2020 contains no data due to COVID\nSource: https://github.com/shoenot/march-madness-games-csv"
  ) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    plot.caption = element_text(hjust = 1,
                                face = "italic",
                                size = 6)
    )

# Filters by the upset value, and I also decided to remove top 4 and 2. Was not adding much visually.          
box_plot_data <- upsets_data |>
  filter(upset, round_of %in% c("64", "32", "16", "8"))

round_label <- c(
  "64" = "64 teams left",
  "32" = "32 teams left",
  "16" = "16 teams left",
  "8" = "8 teams left"
)

#view(box_plot_data)

ggplot(box_plot_data, aes(x = four_year_range, y = seed_difference, fill = four_year_range)) +
  geom_boxplot(alpha = 0.7) +
  stat_boxplot(geom = "errorbar", width = 0.5, color = "black") +
  coord_flip() +
  facet_wrap(~ round_of, ncol = 2, labeller = labeller(round_of = round_label)) +
  labs(
    y = "Seed Difference\n(Seed of winner minus loser)",
    x = "4-year range",
    title = "Upset Magnitudes by 4-year time range & Bracket",
    caption = "Note: 2020 contains no data due to COVID\nSource: https://github.com/shoenot/march-madness-games-csv"
  ) + 
  scale_y_continuous(breaks = seq(0, 12, by = 4), limits = c(0, 15)) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.caption = element_text(hjust = 1,
                                face = "italic",
                                size = 6)
  )
```

## Question 2 Discussion

Based on the results of the heatmap tile plot from 2000-2024, it would appear upsets are occurring more frequently. With 64 teams (the start of the tournament), we can see a small increase in upset frequency over the course of time. The data is indeed richer with 64 teams left, and the trend looks less clear cut as the teams left per round decrease. There are a few notable spikes in upset frequency, especially mid-tournament with 8 teams remaining. Overall, it would appear that in earlier rounds (64, 32, and 16 teams left), upsets are occurring more frequently over time. However, as better teams make it farther in the tournament, such as final 4 and 2, the upset frequency has significantly decreased.

Next, the boxplot measures the magnitude of upsets. This was computed by subtracting the seed difference by matchups, filtered by upsets. I also decided to exclude final 4 and 2 from this visualization. As seen in this visual, first round matchups over the years have seen a lot more volatility with extreme outliers: There are a lot more 16th seed and 15th seed victories in recent times, implying higher upset magnitude. Examining the median and whisker lengths by round over the years seems to reveal a trend: recently, there have been larger upsets with higher variability. By bracket, this upset variability steadily decreases.
